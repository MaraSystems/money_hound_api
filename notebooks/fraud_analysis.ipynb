{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1245e38",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### On `Mobile money` transactions for `Mara Bank`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8563f",
   "metadata": {},
   "source": [
    "## Sections in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355b30c",
   "metadata": {},
   "source": [
    "- Introduction\n",
    "    - Project Overview\n",
    "    - Objectives\n",
    "    - Dataset Background\n",
    "\n",
    "- Data Importation\n",
    "    - Import modules\n",
    "    - Import Datasets\n",
    "    - Set Global Constants\n",
    "\n",
    "- Data Description\n",
    "    - Data Information\n",
    "    - Dataset Shape and Size\n",
    "    - Data Types\n",
    "    - Basic Statistical Summery\n",
    "\n",
    "- Data Wrangling\n",
    "    - Missing Values Analysis\n",
    "    - Outlier Detection\n",
    "    - Handling Inconsistencies\n",
    "\n",
    "- Exploratory Analysis\n",
    "    - Summery Statistics\n",
    "    - Distribution of Data\n",
    "    - Spread of Data\n",
    "    - Trend Analysis\n",
    "    - Correlation of Features\n",
    "\n",
    "- Insights and Findings\n",
    "    - Key Patterns\n",
    "    - Anomalies\n",
    "    - Business Insights\n",
    "    - Recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f41dc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Project Overview\n",
    "- Objectives\n",
    "- Dataset Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2bd7a2",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c796a",
   "metadata": {},
   "source": [
    "Imagine youâ€™re watching millions of transactions flow through `Mara Bank` in Nigeria, like airtime purchases, money transfers, bill payments, all happening in real-time from bustling cities to quiet rural towns.\n",
    "\n",
    "Hidden in this river of activity are patterns and sometimes, suspicious ripples that could be signs of fraud.\n",
    "\n",
    "This project is our detective work. Weâ€™re diving into `Mara Bankâ€™s` mobile money transaction data to uncover how people really use the `mobile banking` system and prepare the ground for building a `fraud detection model`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec1466",
   "metadata": {},
   "source": [
    "### Project Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5cc9c",
   "metadata": {},
   "source": [
    "The Key objectives are:\n",
    "\n",
    "- Clean the noise: Make sure the transaction data is accurate, consistent, and ready for investigation.\n",
    "\n",
    "- Spot the patterns: Study trends in location, time, amount, and type of transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5bc8e",
   "metadata": {},
   "source": [
    "### Background of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4beaa",
   "metadata": {},
   "source": [
    "The dataset was generated mimicing the different scenerios transactions can occur in Nigeria. It contains transactions of diferrent banks, however we will be focusing on the transactions that belongs to `Mara Bank` for this project.\n",
    "\n",
    "This dataset contains the following:\n",
    "\n",
    "- `amount`: The value of the transaction.\n",
    "- `balance`: The account balance after the transaction.\n",
    "- `time`: The timestamp of the transaction.\n",
    "- `holder`: The account number of the transaction's initiator or recipient.\n",
    "- `kyc`: The kyc level of the account\n",
    "- `holder_bvn`: The BVN of the transaction's initiator or recipient.\n",
    "- `holder_bank`: The bank of the related party.\n",
    "- `related`: The account number or entity related to the transaction (e.g., recipient account, ATM bank).\n",
    "- `related_bvn`: The BVN of the related party.\n",
    "- `related_bank`: The bank of the related party.\n",
    "- `state`, `latitude`, `longitude`: Location details of the transaction.\n",
    "- `status`: The outcome of the transaction (e.g., 'SUCCESS', 'FAILED').\n",
    "- `type`: The transaction type (e.g., 'DEBIT', 'CREDIT').\n",
    "- `category`: The specific class of transaction (e.g., 'OPENING', 'WITHDRAWAL', 'PAYMENT', 'TRANSFER', 'REVERSAL', 'BILL').\n",
    "- `channel`: The channel used for the transaction (e.g., 'CARD', 'APP', 'USSD').\n",
    "- `device`: The device used for the transaction (e.g., 'ATM-001', 'MOBILE-003') .\n",
    "- `reference`: A unique identifier for related transactions.\n",
    "- `reported`: Marks reported transactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fb0ee",
   "metadata": {},
   "source": [
    "## Data Importation\n",
    "\n",
    "- Loading Required Libraries\n",
    "- Reading Data Files\n",
    "- Initial Data Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf845c9",
   "metadata": {},
   "source": [
    "### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd16128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb03144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a76ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our custom library\n",
    "from src.lib.analytics import analyst, engineer\n",
    "from src.lib.store.load_data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13413ef",
   "metadata": {},
   "source": [
    "### Reading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transactions dataset for the project \n",
    "df = load_data('transactions.csv', parse_dates=['time'])\n",
    "\n",
    "# load the accounts dataset for the project\n",
    "accounts_df = load_data('accounts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fca35",
   "metadata": {},
   "source": [
    "### Initial data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6019e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8c185",
   "metadata": {},
   "source": [
    "We are only interested in the data for `Steven Salazar Bank`, so we will be extracting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_name = 'Steven Salazar Bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f9f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df.rename(columns={'latitude': 'holder_latitude', 'longitude': 'holder_longitude'}, inplace=True)\n",
    "accounts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_accounts = accounts_df[accounts_df['bank_name'] == bank_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = df[df['holder_bank'] == bank_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge add the kyc and merchant from the account df\n",
    "bank_df = bank_df.merge(bank_accounts[['kyc', 'merchant', 'account_no', 'holder_latitude', 'holder_longitude', 'opening_device']], how='left', left_on='holder', right_on='account_no').drop(columns='account_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de172917",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['holder_bvn'] = bank_df.apply(lambda row: accounts_df[(accounts_df['account_no'] == row['holder']) & (accounts_df['bank_name'] == row['holder_bank'])].squeeze()['bvn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ba78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_bvn(row):\n",
    "    account = accounts_df[(accounts_df['account_no'] == row['related']) & (accounts_df['bank_name'] == row['related_bank'])].squeeze()\n",
    "    return account['bvn'] if not account.empty else row['related_bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bcf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['related_bvn'] = bank_df.apply(get_related_bvn, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a242f29",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "- Missing Values Analysis\n",
    "- Outlier Detection\n",
    "- Handling Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce736801",
   "metadata": {},
   "source": [
    "### Data Information\n",
    "\n",
    "Let's have see the data types and shape of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the basic information about the dataset\n",
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c03bf2",
   "metadata": {},
   "source": [
    "We have let's of categorical values, this will really help with our classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f6d8d",
   "metadata": {},
   "source": [
    "### Dataset shape and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the size of the dataset\n",
    "bank_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13d851",
   "metadata": {},
   "source": [
    "### Dataset Statistics\n",
    "\n",
    "Lets summarize the dataset using summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the format for pandas to display floats\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set the theme for our visualization\n",
    "plt.style.use('dark_background')\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sneak peak statistical summery of the dataset\n",
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2c02f",
   "metadata": {},
   "source": [
    "Looking at this summary, here are the things that stand out.\n",
    "\n",
    "`Amount` \n",
    "- Mean is around 503K while median is around 93K, it skews to the right.\n",
    "- Max is 9.7M which is around 15x of the 75%.\n",
    "- Std is around 940K while mean is 503K, further confirming the right skew.\n",
    "\n",
    "`Balance`\n",
    "- Mean is 21M while median is 2.8M, same skew as amount.\n",
    "- Max is 543B, has much gap on the 75% of more than 50x.\n",
    "- Min is 54.7, no account ever got drained though some came close.\n",
    "\n",
    "`Time`\n",
    "- Ranges from Aug 2023 to Aug 2024. \n",
    "- So the dataset is for 1 year.\n",
    "- We will be extracting (Day, Hour, Week, Month...) from it.\n",
    "\n",
    "`Geo`\n",
    "- Latitude ranges from 4.3 to 14.21\n",
    "- Longitude ranges from -1 to 8.8\n",
    "- That's Nigeria's bounding box (Lagos to Maiduguri)\n",
    "- Mean lat/lon (9.5/3.7), which is central Nigeria.\n",
    "\n",
    "`Kyc`\n",
    "- The min level is 1 and max is 3\n",
    "- This shows that Kyc probabily ranges from 1 to 3\n",
    "\n",
    "`Holder Geo`\n",
    "- Latitude ranges from 5.0 to 137\n",
    "- Longitude ranges from -1 to 8.8\n",
    "- That's Nigeria's bounding box (Lagos to Maiduguri)\n",
    "- Mean lat/lon (9.7/3.6), which is central Nigeria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d1128",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "- Missing Values Analysis\n",
    "- Outlier Analysis\n",
    "- Handling Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652bc0b4",
   "metadata": {},
   "source": [
    "This is a synthetic data, however just for the sake of pete let's still check if anything is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b2eec",
   "metadata": {},
   "source": [
    "Not to say the obvious, there are no no missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45852f2",
   "metadata": {},
   "source": [
    "### Handling Inconsistencies.\n",
    "\n",
    "Since we are using a synthetically generated dataset for this project, we will also be looking into the followining inconsistencies.\n",
    "\n",
    "- Negative amount and balances.\n",
    "- Since we are using reference instead of id, we will check for duplicate reference in unrelated transactions.\n",
    "- Inconsistent reversals\n",
    "- Is the time linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8f8c8",
   "metadata": {},
   "source": [
    "#### Check for negative amount and balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2750e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets name our dataset\n",
    "df_regular = bank_df.copy()\n",
    "\n",
    "# Checking for negative transactions with negative amount or balance\n",
    "df_regular[(df_regular['amount'] < 0) | (df_regular['balance'] < 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f851098",
   "metadata": {},
   "source": [
    "#### Check for duplicate reference\n",
    "\n",
    "The reference, this is used to identifier related transactions.\n",
    "\n",
    "Transactions are related if and only if:\n",
    "- A money gets transfered from one account to another (Debit - Credit)\n",
    "- Money is reversed after a credit or debit.\n",
    "\n",
    "So, given these set of rules for a relationship to exist, nonces can relate only the following number of transactions.\n",
    "- 1 transaction: Single transaction eg. Opening an account, Deposits like Loan from bank\n",
    "- 2 transactions: Credit - Debit, Credit - Reversal, Debit Reversal\n",
    "- 4 transactions: Credit - Debit - Credit Reversal - Debit Reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b008d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the uniqueness of the reference\n",
    "referrence_frequency = df_regular['reference'].value_counts()\n",
    "referrence_frequency.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867e4cc",
   "metadata": {},
   "source": [
    "We do not have any reference that connects unrelated transactions.\n",
    "\n",
    "Let's check for inconsistent reverserals, to do this we need to answer this question - `Are there any reversals with a unique reference?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversals with unique reference\n",
    "df_regular[(df_regular['type'] == 'REVERSAL') & (df_regular['reference'].isin(referrence_frequency[referrence_frequency == 1].index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1656e8e",
   "metadata": {},
   "source": [
    "We don't have any irregular reversals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411ca5b",
   "metadata": {},
   "source": [
    "#### Check if time is linear\n",
    "\n",
    "Now is the time of the transactions linear for each account?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if time is linear\n",
    "df_regular.groupby('holder')['time'].apply(lambda x: x.is_monotonic_increasing).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e404619",
   "metadata": {},
   "source": [
    "Yes, all accounts have linear time. Good ðŸ™‚\n",
    "\n",
    "Let's align our data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1598d",
   "metadata": {},
   "source": [
    "`Latitude`, `Longitude` are floats but should be treated as discrete variables. Hence should be converted to object.\n",
    "\n",
    "`kyc`, `reference` are int but should be treated as categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert latitude and longitude to str\n",
    "df_regular['latitude'] = df_regular['latitude'].astype(str)\n",
    "df_regular['longitude'] = df_regular['longitude'].astype(str)\n",
    "df_regular['holder_latitude'] = df_regular['holder_latitude'].astype(str)\n",
    "df_regular['holder_longitude'] = df_regular['holder_longitude'].astype(str)\n",
    "\n",
    "\n",
    "df_regular['kyc'] = df_regular['kyc'].astype(str)\n",
    "df_regular['reference'] = df_regular['reference'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b846f",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "\n",
    "We need our model to learn very well from the data that we will feeding it, hence we need to remove situations that way too `out of this world` from our dataset.\n",
    "\n",
    "Let's see the spread of the dataset once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce98f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the shape of the dataset?\n",
    "df_regular.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdb8f2",
   "metadata": {},
   "source": [
    "We have removed latitude and longitude from the summary statitics, it is now treated as a discrete feature.\n",
    "\n",
    "Let's visualize these spreads so we can understand them better.\n",
    "\n",
    "We will be needing a special function that will help us with our visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the boxplot to visual the spread of the numeric data\n",
    "columns = df_regular.describe().columns\n",
    "analyst.plotter(\n",
    "    plot=lambda x:\n",
    "        # Set subplots sections\n",
    "        plt.subplot(int(np.ceil(len(columns))), 2, x[0] + 1)\n",
    "\n",
    "        # Set the title of the Plot\n",
    "        and plt.title(x[1])\n",
    "\n",
    "        # Visualize the spread of the features\n",
    "        and sns.boxplot(data=df_regular, x=x[1])\n",
    "\n",
    "        # Set the label of the x-axis\n",
    "        and plt.xlabel(x[1]),\n",
    "    columns=columns,\n",
    "    figsize=(20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fc060",
   "metadata": {},
   "source": [
    "We will handle the outliers by scaling the balanace and amount down the using log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular['amount_log'] = np.log(df_regular['amount'])\n",
    "df_regular['balance_log'] = np.log(df_regular['balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the boxplot to visual the spread of the numeric data\n",
    "columns = df_regular.describe().columns\n",
    "analyst.plotter(\n",
    "    plot=lambda x:\n",
    "        # Set subplots sections\n",
    "        plt.subplot(int(np.ceil(len(columns))), 2, x[0] + 1)\n",
    "\n",
    "        # Set the title of the Plot\n",
    "        and plt.title(x[1])\n",
    "\n",
    "        # Visualize the spread of the features\n",
    "        and sns.boxplot(data=df_regular, x=x[1])\n",
    "\n",
    "        # Set the label of the x-axis\n",
    "        and plt.xlabel(x[1]),\n",
    "    columns=columns,\n",
    "    figsize=(20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801eb743",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Lets get to understand our data.\n",
    "\n",
    "- Summary Statistics\n",
    "- Correlation of Features\n",
    "- Distribution of Data\n",
    "- Spread of Data\n",
    "- Trend Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we begin, let's name our df properly\n",
    "df_eda = df_regular.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32d5c7",
   "metadata": {},
   "source": [
    "#### Extracting Periodic features\n",
    "\n",
    "Let's feed another curiousity we have been holding. When did most transactions occur at?\n",
    "\n",
    "To do this we will have to extract the hour, day and month feature ealier than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the hour\n",
    "df_eda['hour'] = df_eda['time'].dt.hour.astype(str).str.zfill(2)\n",
    "\n",
    "# Extracting the day\n",
    "df_eda['week_day'] = df_eda['time'].dt.day_name()\n",
    "\n",
    "# Extracting the month\n",
    "df_eda['month'] = df_eda['time'].dt.month_name()\n",
    "\n",
    "# Extracting the date\n",
    "df_eda['date'] = df_eda['time'].dt.date\n",
    "\n",
    "# Extracting the month day\n",
    "df_eda['month_day'] = df_eda['time'].dt.day.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779de1f5",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4830203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take another look at the summary statistics\n",
    "df_eda.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e44d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the statistics of the categorical features.\n",
    "df_eda.describe(include=['object', 'bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb5420",
   "metadata": {},
   "source": [
    "Things that stand out in this summary.\n",
    "\n",
    "- There are `793` different accounts that transacted within the time of this transactions.\n",
    "\n",
    "- All these `793` accounts belong to only `763` users, some users own multiple accounts.\n",
    "\n",
    "- There are `50` related banks, which corresponds to the total number of banks in the simulation.\n",
    "\n",
    "- There are `6` categories of tranactions that fall under the `2` types of transactions (Debit/Credit)\n",
    "\n",
    "- A total of `7087` devices where also used accross `3` channels were used.\n",
    "\n",
    "- There were `17028` related transactions based on the unique `reference` in the dataset.\n",
    "\n",
    "- The transaction spans accross `37` unique states, suggesting it is all accross Nigeria.\n",
    "\n",
    "- The most transactions took place in `Gombe`. (Ballers ðŸ’°). Is the there a hotspot there?\n",
    "\n",
    "- The most frequent type and category of transactions are `DEBIT` and `WITHDRAWAL` respectively. Could there be more outflow than inflow?\n",
    "\n",
    "- Most transactions were not reported, we will see the proportion later in this notebook.\n",
    "\n",
    "- `January` is the most frequent month, though the day with most transactions is in `October` on `2025-04-06`\n",
    "\n",
    "- `Month` day of `24` has the most frequent transactions.\n",
    "\n",
    "- There is only 1 holder bank, `Mara Bank` so we will drop the column\n",
    "\n",
    "- Most users are of `KYC` leve of `3`.\n",
    "\n",
    "- `Friday` is the most active day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f94b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.drop(columns='holder_bank', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a152b",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Before we continue on our exploration, let's ask a vital question early.\n",
    "\n",
    "- Do our `data` points have any form of `relationship` with each other.\n",
    "\n",
    "- If they do, what could be the `reason` for that relationship to exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcd2a4",
   "metadata": {},
   "source": [
    "##### Correlation of all features\n",
    "\n",
    "Let's see how all our features are correlating with one another.\n",
    "\n",
    "To do this we need to encode the categorical/discrete features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47091f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7830907",
   "metadata": {},
   "source": [
    "Latitude and Longitude are numberical, however they are actually discrete variables, hence we will encode them before correlating.\n",
    "\n",
    "Also, time is a date variable which is an ordinal and will be treated as a continious variable.\n",
    "\n",
    "Hence our continious variables include `time`, `amount`, `balance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200a330",
   "metadata": {},
   "source": [
    "##### Let's encode the discrete features so we can correlate them with other features.\n",
    "\n",
    "We will be using a special function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the discrete features\n",
    "discrete_features = df_eda.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the discrete features\n",
    "df_corr = engineer.encoder(df_eda, discrete_features)\n",
    "\n",
    "# Concatinate the encoded discrete features with the non discrete features\n",
    "df_corr = pd.concat([df_eda[['amount_log', 'balance_log', 'time']], df_corr], axis=1)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47953bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate the features with each other\n",
    "corr_matrix = df_corr.corr(method='pearson')\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7343af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(data=corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea66f43",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- Strong positive correlation between amount and balance suggests transaction values drive balances.\n",
    "\n",
    "- time and date correlates well with the user features like holder, related, related_bvn, and holder_bvn hinting at potential redundancy or leakage.\n",
    "\n",
    "- Negative correlation between month and time suggests seasonality impacts transaction timing.\n",
    "\n",
    "- type and category show a strong positive correlation, implying categories belong to different types.\n",
    "\n",
    "- Device usage (device) correlates moderately with time, useful for time-device fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix\n",
    "analyst.plotter(\n",
    "    plot=lambda x:\n",
    "        # Set subplots sections\n",
    "        plt.subplot(int(np.floor(len(corr_matrix.columns)/2)), 3, x[0] + 1)\n",
    "\n",
    "        # Visualize the correlation of the features\n",
    "        and sns.barplot(data=corr_matrix, x=corr_matrix.index, y=x[1])\n",
    "\n",
    "        # Set the plot title\n",
    "        and plt.title(f'Correlation of {x[1]}')\n",
    "\n",
    "        # Set x lable\n",
    "        and plt.xlabel('Features')\n",
    "\n",
    "        # Set y lable\n",
    "        and plt.ylabel('Correlation')\n",
    "        \n",
    "        and plt.tick_params(axis='x', rotation=90),\n",
    "\n",
    "    # Set the figsize\n",
    "    figsize=(20, 30),\n",
    "    columns=corr_matrix.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd52ab",
   "metadata": {},
   "source": [
    "Visualizing the correlations, things are getting a lot more clearer.\n",
    "\n",
    "We will now prioritize highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_correlation = analyst.bounded_correlation(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "analyst.plot_bounded_correlation(interesting_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5bfa6",
   "metadata": {},
   "source": [
    "Nice, now we have the correlations that we are interested in, what do we see?\n",
    "\n",
    "- `Amount` and `Balance`: Show very strong mutual positive correlation.\n",
    "\n",
    "- `Holder` & `Holder BVN`: Both highly correlate positively with `time` and `date`.\n",
    "\n",
    "- `Related` & `Related BVN`: Exhibit a very strong positive correlation with each other.\n",
    "\n",
    "- `Status` & `Type`: Are notably correlated, especially with `category`.\n",
    "\n",
    "- `Device` & `Month`: Consistently show minimal to weak correlations overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3e220",
   "metadata": {},
   "source": [
    "Let's get the distribution of features with there correlation with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlations within out threshold\n",
    "valued_correlations = analyst.bounded_correlation(corr_matrix)\n",
    "\n",
    "# Count and sum the correlations of each feature\n",
    "valued_correlations_count = {x: {'count': len(valued_correlations[x]), 'sum': sum(abs(valued_correlations[x]))} for x in valued_correlations}\n",
    "\n",
    "# Convert it to a dataframe\n",
    "valued_corr_df = pd.DataFrame(valued_correlations_count).transpose().sort_values(by='count', ascending=False).reset_index(names='feature')\n",
    "\n",
    "valued_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the the correlations\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.title('Correlation Strength')\n",
    "sns.scatterplot(data=valued_corr_df, x='count', y='sum', hue='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02efb5",
   "metadata": {},
   "source": [
    "Things that stand out from this plot:\n",
    "\n",
    "- Strongest Correlations: Features `holder`, `time`, `holder_bvn`, `month`, and `date` show the highest correlations with `holder` as the strongest.\n",
    "\n",
    "- Weakest Correlations: `Amount` and `category` consistently exhibit very low correlation strength across all counts.\n",
    "\n",
    "- Variable Correlation Strength: Most features display varying correlation strengths depending on the `count` value.\n",
    "\n",
    "- Increasing Count, Increasing Strength: For the most correlated features, strength generally increases with higher `count`.\n",
    "\n",
    "- Outliers in Correlation: `Related` and `related_bvn` show moderate correlation, unlike others at higher counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513b5e5",
   "metadata": {},
   "source": [
    "### Distribution of Data\n",
    "\n",
    "Let's visualize the distibution of the continious and discrete features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f438aff",
   "metadata": {},
   "source": [
    "#### General View\n",
    "\n",
    "Let's look at our data from the outside to the inside, this will enable use get a better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the details of our dataset to choose the columns to visualize\n",
    "df_eda.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b90b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the continious features.\n",
    "columns = ['amount_log', 'balance_log', 'time']\n",
    "\n",
    "analyst.plotter(\n",
    "    plot=lambda x:\n",
    "        # Set subplots sections\n",
    "        plt.subplot(len(columns), 2, x[0] + 1)\n",
    "\n",
    "        # Visualize the distribution of the features\n",
    "        and sns.histplot(data=df_eda, x=x[1], kde=True)\n",
    "\n",
    "        # Set the plot title\n",
    "        and plt.title(f'Distribution of {x[1]}')\n",
    "\n",
    "        # Set X lable\n",
    "        and plt.xlabel(x[1].capitalize())\n",
    "\n",
    "        # Set Y lable\n",
    "        and plt.ylabel('Frequency'),\n",
    "\n",
    "    # Set the figsize\n",
    "    figsize=(20, 10),\n",
    "    columns=columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca12600",
   "metadata": {},
   "source": [
    "Things that stand out.\n",
    "\n",
    "- `Amount`: Heavily right-skewed; most transactions are for small amounts.\n",
    "\n",
    "- `Balance`: Right-skewed, similar to amount; many transactions have low balances.\n",
    "\n",
    "- `Time`: Frequency is relatively uniform across months (2024-2025).\n",
    "\n",
    "- Both `amount` & `balance` distributions show a sharp drop-off after small values.\n",
    "\n",
    "- No strong trend or seasonality evident in the time distribution plot.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the discrete features.\n",
    "columns = [\n",
    "    'status',\n",
    "    'type',\n",
    "    'category',\n",
    "    'reported',\n",
    "    'channel',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'hour',\n",
    "    'week_day',\n",
    "    'month',\n",
    "    'date',\n",
    "    'month_day',\n",
    "    'kyc',\n",
    "    'merchant'\n",
    "]\n",
    "\n",
    "analyst.plotter(\n",
    "    plot=lambda x:\n",
    "        # Set subplots sections\n",
    "        plt.subplot(int(np.floor(len(columns))), 2, x[0] + 1)\n",
    "\n",
    "        # Visualize the distribution of the features\n",
    "        and sns.countplot(data=df_eda, x=x[1])\n",
    "\n",
    "        # Set the plot title\n",
    "        and plt.title(f'Distribution of {x[1]}')\n",
    "\n",
    "        # Set x lable\n",
    "        and plt.xlabel(x[1].capitalize())\n",
    "\n",
    "        # Set y lable\n",
    "        and plt.ylabel('frequency')\n",
    "\n",
    "        and plt.tick_params(axis='x', rotation=90),\n",
    "\n",
    "    # Set the figsize\n",
    "    figsize=(20, 40),\n",
    "    columns=columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1327149",
   "metadata": {},
   "source": [
    "##### Observations.\n",
    "\n",
    "- Majority of transactions `succeed`; only a small fraction `fail`, skewing fraud detection toward anomalies.\n",
    "\n",
    "- `Debits` heavily outnumber `credits`, but withdrawals and reversals show potential fraud-risk categories.\n",
    "\n",
    "- Most activity comes from card-based `channels`; APP/USSD volumes are small but fraud-prone.\n",
    "\n",
    "- `Reported` fraud cases are few, creating high class imbalance and challenge for supervised models.\n",
    "\n",
    "- `KYC` levels are few at level 4; low levels are frequent, signaling very few people could attain the level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de479d",
   "metadata": {},
   "source": [
    "Well, there we have it, there are more outflows than inflows for this through the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64593468",
   "metadata": {},
   "source": [
    "#### CashFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9dcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cashflow\n",
    "analyst.plot_cashflow(df_eda, ['hour', 'week_day', 'month', 'month_day', 'kyc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475965db",
   "metadata": {},
   "source": [
    "Observing this plot, here are the things that stand out.\n",
    "\n",
    "- Overall negative `netflow` indicates accross all features\n",
    "\n",
    "- `Cashflow` varies significantly by `state`, with `Kaduna` & `Ogun` showing no `netflows`.\n",
    "\n",
    "- There is no decline of activities in `week_day`, `month` or `hour`. The is a little fluctuations in `month_day` however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc49c9e",
   "metadata": {},
   "source": [
    "#### Distribution of features with type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution by type\n",
    "plt.figure(figsize=(20, 20))\n",
    "analyst.plot_distribution(df_eda, ['channel', 'category', 'amount', 'reported', 'date', 'holder', 'kyc'], 'type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe71c0d",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- There is class inbalance in `category`, it needs the `dimension` to be reduced.\n",
    "\n",
    "- Accross all features, there is a huge gap in transaction `type`, with `debit` being almost 2x of `credit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31085f8",
   "metadata": {},
   "source": [
    "#### Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution by category\n",
    "plt.figure(figsize=(20, 20))\n",
    "analyst.plot_distribution(df_eda, ['amount_log', 'balance_log', 'date', 'month_day', 'channel', 'kyc'], 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f0eea",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- `Amount` and `Balance`: Most transactions, especially withdrawals and deposits, are of low value.\n",
    "\n",
    "- `Date`: Transaction frequencies show fluctuations over time, with withdrawals and deposits consistently dominant.\n",
    "\n",
    "- Channel: APP is the primary channels, with APP heavily used for withdrawals and deposits. USSD/CARD is less utilized.\n",
    "\n",
    "- State: Transaction volumes vary by state, with Gombe and Delter showing high activity.\n",
    "\n",
    "- Month Day: Transaction frequencies are relatively consistent throughout the month, with no strong daily patterns for any category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d8888",
   "metadata": {},
   "source": [
    "#### Channel Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution by category\n",
    "plt.figure(figsize=(20, 30))\n",
    "analyst.plot_distribution(df_eda, ['amount_log', 'balance_log', 'hour', 'month_day', 'channel', 'holder', 'kyc'], 'channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32b674",
   "metadata": {},
   "source": [
    "Observations: \n",
    "\n",
    "- Amount/Balance: Lower transaction amounts are most frequent.\n",
    "\n",
    "- Hour: Activity levels fluctuate throughout the day for each channel.\n",
    "\n",
    "- Month Day: Usage patterns differ across days of the month.\n",
    "\n",
    "- Overall Channel Usage: A clear comparison of the total volume handled by each channel.\n",
    "\n",
    "- Holder: Shows how different user relate to specific channels, with Card being the favourite option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc9c65",
   "metadata": {},
   "source": [
    "#### Reported Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "analyst.plot_distribution(df_eda, ['amount_log', 'balance_log', 'date', 'week_day', 'channel', 'category', 'holder', 'kyc'], 'reported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a07801",
   "metadata": {},
   "source": [
    "- The majority of transactions involve small amounts, with frequency sharply decreasing as the transaction amount increases.\n",
    "\n",
    "- Similarly, most account balances are relatively low, with fewer accounts holding large balances.\n",
    "\n",
    "- \"Withdrawal\" transactions is significantly more frequent than other categories like \"Deposit\" or \"Payment.\"\n",
    "\n",
    "- \"Opening\" transactions are the least frequent among the displayed categories.\n",
    "\n",
    "- Transactions are consistently distributed across the week, indicating a similar level of activity throughout the week.\n",
    "\n",
    "- Mobile banking channels (\"APP\") appear to be the most frequently used for transactions, followed by \"CARD\" and then \"USSD.\"\n",
    "\n",
    "- Transaction frequency is relatively low for most account holders, with a few holders showing a higher frequency of transactions.\n",
    "\n",
    "- The frequency of transactions over date shows fluctuations but no clear, strong upward or downward trend across the observed period.\n",
    "\n",
    "- Certain states like Gombe, and Delta show a higher frequency of transactions compared to others like Abia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894c560",
   "metadata": {},
   "source": [
    "### Spread of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the spread of the data\n",
    "plt.figure(figsize=(20, 40))\n",
    "analyst.plot_scatter(df_eda, 'amount_log', ['balance_log', 'channel', 'category', 'month', 'week_day', 'month_day', 'hour', 'date', 'kyc'], 'reported', 1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f451d",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- No opening category of transaction was reported\n",
    "\n",
    "- Level 3 KYC has the least reported transaction\n",
    "\n",
    "- Transactions are not reported as much on weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "analyst.plot_scatter(df_eda, 'balance_log', ['amount_log', 'channel', 'category', 'month', 'week_day', 'month_day', 'hour', 'date', 'kyc'], 'reported', 1e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cb349",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- There is an even spread of reported transactions accross all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad35ea3",
   "metadata": {},
   "source": [
    "### Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst.plot_trend(df_eda, ['date', 'hour', 'month', 'week_day', 'month_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfd89d",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- `7am` is the most active of all the hours.\n",
    "- `January` is a very active month.\n",
    "- `Friday` is the most active off all days with Monday as the least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.to_csv(f'../datasets/analyzed_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0709c18",
   "metadata": {},
   "source": [
    "## Insights and Findings\n",
    "    \n",
    "- Key Patterns\n",
    "- Anomalies\n",
    "- Business Insights\n",
    "- Recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da45a42",
   "metadata": {},
   "source": [
    "### Key Patterns\n",
    "\n",
    "- Amount â†” Balance lockstep: Strong positive correlation; high amounts typically move balances in sync.\n",
    "\n",
    "- Temporal uniformity: Activity is broadly even by hour/weekday/month.\n",
    "\n",
    "- Debit & Withdrawal gravity: Debits dominate; Withdrawals are the most frequent category.\n",
    "\n",
    "- KYC skew: KYC Level 4 heavily deconcentrated; Lower KYC levels are more frequent.\n",
    "\n",
    "- Geo concentration: Transactions span 37 states; Gombe/Delta emerge as volume hot spots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26192caf",
   "metadata": {},
   "source": [
    "### Anomalies\n",
    "\n",
    "- Heavy right-skew: Amount and balance distributions contain many high-end outliers (IQR-trimmed).\n",
    "\n",
    "- reference integrity edge cases: Reversal/transfer pairings must be 1/2/4 events, flag any other counts.\n",
    "\n",
    "- Cashflow dips: Net outflow pockets (e.g., KYC 3 cohorts) suggest leakage or behavioral anomalies.\n",
    "\n",
    "- Device/Channel bursts: Localized spikes by device/channel may indicate scripted or bot-like activity.\n",
    "\n",
    "- Time cliffs: Spikes in the morning, maybe something fishy is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28380500",
   "metadata": {},
   "source": [
    "### Business Insights\n",
    "\n",
    "- Risk concentration at low KYC: Disproportionate activity with low verification = elevated fraud exposure.\n",
    "\n",
    "- Operational focus states: Gombe/Delta high volumes merit tailored limits and monitoring rules.\n",
    "\n",
    "- Channel strategy: APP drives withdrawals; CARD steady for everyday useâ€”tune controls per channel.\n",
    "\n",
    "- Sparse â€œreportedâ€ labels: Supervised models will be label-starved; lean on anomaly/PU learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad0fad",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "- Tiered limits by KYC: Stricter per-txn/day caps and velocity rules for KYC 3; relax for 1,2 and 4.\n",
    "\n",
    "- reference policy checks: Enforce 1/2/4-event schemas; auto flag any reference with unexpected counts.\n",
    "\n",
    "- Adaptive outlier bounds: Maintain IQR based caps per state/channel/hour; update weekly.\n",
    "\n",
    "- Behavioral features: Add rolling velocity, peer group z-scores, and device consistency signals.\n",
    "\n",
    "- Modeling stack: Use Isolation Forest for prefiltering â†’ Logistic Regression/XGBoost on flagged sets.\n",
    "\n",
    "- Hotspot playbooks: For Yobe/Oyo, deploy tighter ATM/POS withdrawal thresholds + step-up KYC.\n",
    "\n",
    "- Explainability & feedback: SHAP for triage; analyst feedback loops to enrich â€œreportedâ€ labels.\n",
    "\n",
    "- Real-time guardrails: Rule combos (large amount Ã— new device Ã— late hour Ã— cross-state) = hard blocks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
